{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"title_ID\"></a>\n",
    "# JWST Data Products: Calibrated Individual Exposures and WCS\n",
    "--------------------------------------------------------------\n",
    "**Author**: Alicia Canipe (acanipe@stsci.edu) with exerpts from Espinoza, Sosey | **Latest update**: March 30, 2021.\n",
    "\n",
    "## Table of contents\n",
    "1. [Introduction](#intro)\n",
    "   1. [Resources](#resources)   \n",
    "2. [Data in MAST](#mast)\n",
    "3. [Example data for this exercise](#example)\n",
    "4. [Data products: stage 1 (detector corrections)](#stage1)\n",
    "    1. [Input](#s1-input)\n",
    "    2. [Output](#s1-output)\n",
    "    3. [Examining the products](#s1-examine)\n",
    "5. [Associations](#associations)\n",
    "6. [Data products: stage 2 (calibrated exposures)](#stage2)\n",
    "    1. [Imaging](#s2-imaging)\n",
    "        1. [Input](#s2-imaging-input)\n",
    "        2. [Output](#s2-imaging-output)\n",
    "    2. [Spectroscopy](#s2-spectroscopy)\n",
    "        1. [Input](#s2-spectroscopy-input)\n",
    "        2. [Output](#s2-spectroscopy-output)\n",
    "7. [WCS deep dive](#wcs)\n",
    "8. [Exercise](#exercise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.<font color='white'>-</font>Introduction <a class=\"anchor\" id=\"intro\"></a>\n",
    "------------------\n",
    "\n",
    "Welcome to the second module about JWST data products! In this module, we will take a deeper dive into how JWST data products change through different stages of the JWST Calibration Pipeline (hereafter, the pipeline). We will start by examining the data products for Stage 1 and Stage 2 processing, and end by checking out the WCS information. In the third and final module for this JWebbinar, we'll continue on to explore Stage 3 data products. \n",
    "\n",
    "### A.<font color='white'>-</font>Resources<a class=\"anchor\" id=\"resources\"></a>\n",
    "\n",
    "Visit the [webpage for JWebbinars](https://www.stsci.edu/jwst/science-execution/jwebbinars) to find resources for:\n",
    "* The Mikulski Archive for Space Telescopes (MAST) \n",
    "* JWST Documentation (JDox) for JWST data products\n",
    "* The most up-to-date information about JWST data products in the pipeline readthedocs\n",
    "* Pipeline roadmaps for when to recalibrate your data\n",
    "\n",
    "Before we begin, import the libraries used in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module with functions to get information about objects:\n",
    "import os\n",
    "import inspect\n",
    "import asdf \n",
    "import pprint\n",
    "\n",
    "# Numpy library:\n",
    "import numpy as np\n",
    "\n",
    "# Scipy tools\n",
    "from scipy.signal import medfilt\n",
    "\n",
    "# Astropy tools:\n",
    "from astropy.utils.data import download_file\n",
    "from astropy.io import fits\n",
    "\n",
    "# The JWST models:\n",
    "from jwst import datamodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And set up matplotlib for plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Use this version if you want interactive plots\n",
    "# %matplotlib notebook\n",
    "\n",
    "# Use this version for non-interactive plots (easier scrolling of the notebook)\n",
    "%matplotlib inline\n",
    "\n",
    "# These gymnastics are needed to make the sizes of the figures\n",
    "# be the same in both the inline and notebook versions\n",
    "%config InlineBackend.print_figure_kwargs = {'bbox_inches': None}\n",
    "\n",
    "mpl.rcParams['savefig.dpi'] = 80\n",
    "mpl.rcParams['figure.dpi'] = 80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, create some convenience functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image(data_2d, vmin, vmax, xpixel=None, ypixel=None, title=None):\n",
    "    ''' Function to generate a 2D image of the data, \n",
    "    with an option to highlight a specific pixel.\n",
    "    '''\n",
    "    \n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = plt.subplot()\n",
    "    plt.imshow(data_2d, origin='lower', cmap='gray', vmin=vmin, vmax=vmax)\n",
    "    \n",
    "    if xpixel and ypixel:\n",
    "        plt.plot(xpixel, ypixel, marker='o', color='red', label='Selected Pixel')\n",
    "\n",
    "    plt.xlabel('Pixel column')\n",
    "    plt.ylabel('Pixel row')\n",
    "    \n",
    "    if title:\n",
    "        plt.title(title)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.subplots_adjust(left=0.15)\n",
    "    plt.colorbar(label='DN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_slit_image(data_2d, slit_number, vmin=None, vmax=None, title=None):\n",
    "    ''' Function to generate a 2D image of a particular slit.\n",
    "    '''\n",
    "    \n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = plt.subplot()\n",
    "    \n",
    "    if vmin and vmax:\n",
    "        plt.imshow(data_2d.slits[slit_number].data, origin='lower', cmap='gray', vmin=vmin, vmax=vmax)\n",
    "        plt.colorbar(label='DN/sec')        \n",
    "    else:\n",
    "        minimum = data_2d.slits[slit_number].data.min()\n",
    "        maximum = data_2d.slits[slit_number].data.max()\n",
    "        plt.imshow(data_2d.slits[slit_number].data, origin='lower', cmap='gray', vmin=minimum, vmax=maximum)\n",
    "        plt.colorbar(label='DN/sec')        \n",
    "\n",
    "    plt.xlabel('Pixel column')\n",
    "    plt.ylabel('Pixel row')\n",
    "    \n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    else:\n",
    "        title = \"object {} order = {}\".format(data_2d.slits[slit_number].source_id, \n",
    "                                              data_2d.slits[slit_number].meta.wcsinfo.spectral_order)\n",
    "        plt.title(title)\n",
    "\n",
    "    plt.subplots_adjust(left=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ramp(groups, signal, xpixel=None, ypixel=None, title=None):\n",
    "    ''' Function to generate the ramp for pixel.\n",
    "    '''\n",
    "    \n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = plt.subplot()\n",
    "    if xpixel and ypixel:\n",
    "            plt.plot(groups, signal, marker='o', label='Pixel ('+str(xpixel)+','+str(ypixel)+')') \n",
    "            plt.legend(loc=2)\n",
    "\n",
    "    else:\n",
    "        plt.plot(groups, signal, marker='o')\n",
    "        \n",
    "    plt.xlabel('Groups')\n",
    "    plt.ylabel('Signal (DN)')\n",
    "    plt.subplots_adjust(left=0.15)\n",
    "    \n",
    "    if title:\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_column(data_2d, column, title=None):\n",
    "    ''' Function to generate a plot for one column in a dispersed image.\n",
    "    '''\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    ax = plt.subplot()\n",
    "    plt.plot(data_2d[:,column], label='Column '+str(column))\n",
    "        \n",
    "    plt.xlabel('Pixel row')\n",
    "    plt.ylabel('Column values')\n",
    "    plt.subplots_adjust(left=0.15)\n",
    "    \n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    else:\n",
    "        plt.title('WFSS plot of one column in dispersed image')\n",
    "        \n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectra(spec, number, median_filter=None, title=None):\n",
    "    ''' Function to generate the spectrum for a slit.\n",
    "    '''\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    ax = plt.subplot()\n",
    "    \n",
    "    if median_filter:\n",
    "        plt.plot(spec.spec[number].spec_table['WAVELENGTH'], medfilt(spec.spec[number].spec_table['FLUX'],median_filter)) \n",
    "        \n",
    "    else: \n",
    "        plt.plot(spec.spec[number].spec_table['WAVELENGTH'], spec.spec[number].spec_table['FLUX']) \n",
    "\n",
    "    \n",
    "    plt.xlabel('Wavelength (um)')\n",
    "    plt.ylabel('Flux')\n",
    "    \n",
    "    plt.subplots_adjust(left=0.15)\n",
    "    \n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    else:\n",
    "        title='Spectrum for Source '+str(spec.spec[number].source_id)+', Spectral Order '+str(spec.spec[number].spectral_order)\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.<font color='white'>-</font>Data in MAST <a class=\"anchor\" id=\"mast\"></a>\n",
    "------------------\n",
    "\n",
    "The JWST Data Management System (DMS) produces many products for each JWST observation, including the science files generated by the pipeline. The exact type and number of products depends on the instrument, its configuration, and observing mode. Observers should consult the [MAST documentation for information about standard data products](https://jwst-docs.stsci.edu/obtaining-data/data-discovery#DataDiscovery-Dataproducttypes). \n",
    "\n",
    "Of the many different data products produced by the calibration pipeline, most observers will find the science data files in MAST to be sufficient for their analysis. However, other data products such as guide star data, associations, and engineering data are also available. \n",
    "\n",
    "Standard science data files include:\n",
    "\n",
    "* [uncalibrated raw data](https://jwst-pipeline.readthedocs.io/en/stable/jwst/data_products/science_products.html#uncalibrated-raw-data-uncal), identified by the suffix ```uncal```\n",
    "* [countrate data](https://jwst-pipeline.readthedocs.io/en/stable/jwst/data_products/science_products.html#countrate-data-rate-and-rateints) produced by applying the Stage 1 (detector-level) corrections in order to compute count rates from the original accumulating signal ramps, identified by the suffix ```rate``` or ```rateints```\n",
    "* [calibrated single exposures](https://jwst-pipeline.readthedocs.io/en/stable/jwst/data_products/science_products.html#calibrated-data-cal-and-calints), identified by the suffix ```cal```\n",
    "* [resampled and/or combined exposures](https://jwst-pipeline.readthedocs.io/en/stable/jwst/data_products/science_products.html#resampled-2-d-data-i2d-and-s2d), identified by the suffixes ```i2d``` or ```s2d```\n",
    "* [extracted spectroscopic 1D data](https://jwst-pipeline.readthedocs.io/en/stable/jwst/data_products/science_products.html#extracted-1-d-spectroscopic-data-x1d-and-x1dints), identified by the suffixes ```x1d``` or ```c1d```\n",
    "\n",
    "In addition, there are also [several other products depending on the observing mode](https://jwst-pipeline.readthedocs.io/en/stable/jwst/data_products/science_products.html#source-catalog-cat), such as source and photometry catalogs, stacked PSF data, and NIRISS AMI derived data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.<font color='white'>-</font>Example data for this exercise <a class=\"anchor\" id=\"example\"></a>\n",
    "------------------\n",
    "\n",
    "For this module, we will use calibrated NIRCam simulated imaging and wide field slitless spectroscopy (WFSS) exposures that are stored in Box. Let's grab the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rate_file = [\"https://stsci.box.com/shared/static/h30hhwhu4ihlhqjnlhbblx07wnitoytd.fits\", \n",
    "             \"example_nircam_imaging_rate.fits\"]\n",
    "rateints_file = [\"https://stsci.box.com/shared/static/jh937bjqodqhfobhpemnbqt4jax6d6j4.fits\", \n",
    "                 \"example_nircam_imaging_rateints.fits\"]\n",
    "ramp_file = [\"https://stsci.box.com/shared/static/x7d0ldm7bp683p5yyi2buvphjcckujbe.fits\",\n",
    "             \"example_nircam_imaging_ramp.fits\"]\n",
    "wfss_rate_file = [\"https://stsci.box.com/shared/static/d5k9z5j05dgfv6ljgie483w21kmpevni.fits\",\n",
    "                  \"example_nircam_wfss_rate.fits\"]\n",
    "cal_file = [\"https://stsci.box.com/shared/static/8g15cxb3nri47l3bx22mjtdw3yt8xxiv.fits\",\n",
    "            \"example_nircam_imaging_cal.fits\"]\n",
    "wfss_cal_file = [\"https://stsci.box.com/shared/static/pqgt98wsjz16av3768756ierahzqn8w7.fits\",\n",
    "                 \"example_nircam_wfss_cal.fits\"]\n",
    "wfss_x1d_file = [\"https://stsci.box.com/shared/static/fjzq3dm2kgp2ttoptxwe9yfghmxxxz89.fits\",\n",
    "                 \"example_nircam_wfss_x1d.fits\"]\n",
    "demo_ex_file = [\"https://stsci.box.com/shared/static/6vn402728z12cyx6czdt5hpaxa071aek.fits\",\n",
    "                \"example_exercise_cal.fits\"]\n",
    "\n",
    "all_files = [rate_file, rateints_file, ramp_file, cal_file,\n",
    "             wfss_rate_file, wfss_cal_file, wfss_x1d_file,\n",
    "             demo_ex_file]\n",
    "\n",
    "for file in all_files:\n",
    "    demo_file = download_file(file[0])\n",
    "    \n",
    "    # Save the file so that we can use it later\n",
    "    with fits.open(demo_file) as f:\n",
    "        f.writeto(file[1], overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.<font color='white'>-</font>Data products: stage 1 (detector corrections)<a class=\"anchor\" id=\"stage1\"></a>\n",
    "------------------\n",
    "\n",
    "All JWST data, regardless of the instrument or mode (with the exception of a few specific engineering or calibration cases), is processed through the CALWEBB_DETECTOR1 module, which is Stage 1 of the pipeline. A number of instrument signatures are accounted for in this stage, such as bias corrections and cosmic ray flagging, and slopes are fit to the corrected ramps. More information can be found in the [JWST User Documentation for CALWEBB_DETECTOR1](https://jwst-docs.stsci.edu/jwst-data-reduction-pipeline/algorithm-documentation/stages-of-processing/calwebb_detector1). We also have a full list of data product types and the units of the data for each product [in the documentation](https://jwst-pipeline.readthedocs.io/en/latest/jwst/data_products/product_types.html#data-product-types). \n",
    "\n",
    "### A.<font color='white'>-</font>Input<a class=\"anchor\" id=\"s1-input\"></a>\n",
    "\n",
    "The inputs to this stage are listed below.\n",
    "\n",
    "* **4D raw data**\n",
    "    * **Data model**: RampModel. \n",
    "    * **File suffix**: ```_uncal```\n",
    "    * **Description**: A single raw 4D exposure that contains the original raw data from all detector readouts in the exposure (ncols x nrows x ngroups x nintegrations) \n",
    "\n",
    "\n",
    "\n",
    "### B.<font color='white'>-</font>Output<a class=\"anchor\" id=\"s1-output\"></a>\n",
    "\n",
    "The outputs of this stage are listed below.\n",
    "\n",
    "* **2D countrate product**\n",
    "    * **Data model**: ImageModel or IFUImageModel\n",
    "    * **File suffix**: ```_rate```\n",
    "    * **Description**: All types of inputs result in a 2D countrate product, containing the average over all integrations in an exposure. This product is passed along to subsequent pipeline modules for all non-time series and non-coronagraphic exposures. For MIRI MRS and NIRSpec IFU, the output data model will be IFUImageModel, while all others will be ImageModel.\n",
    "    \n",
    "    \n",
    "* **3D countrate product**\n",
    "    * Data model: CubeModel\n",
    "    * File suffix: ```_rateints```\n",
    "    * Description: A 3D countrate product is created that contains the individual results of each integration. The 2D countrate images for each integration are stacked along the 3rd axis of the data cubes (ncols x nrows x nints). The 3D ```_rateints``` product is passed along to pipeline modules for all time series and coronagraphic exposures. \n",
    "    \n",
    "   \n",
    "* (optional) **4D corrected ramp**\n",
    "    * **Data model**: RampModel\n",
    "    * **File suffix**: ```_ramp```\n",
    "    * **Description**: Result of applying all pipeline steps up through the jump (cosmic ray detection) step, to produce corrected and cosmic ray-flagged 4D ramp data, which will have the same data dimensions as the input raw 4D data (ncols x nrows x ngroups x nints). This file is not created by default, so a user must manually run the pipeline and set the argument ```--save_calibrated_ramp``` to True. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C.<font color='white'>-</font>Examining the products<a class=\"anchor\" id=\"s1-examine\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a closer look at some data products. As our first example, we can grab the ```rate``` and ```rateints``` data products for the simulation we used in module 1. Looking above, we can see that these types of data use the ImageModel and the CubeModel, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data into models (use: rate_image, rateints_cube)\n",
    "rate_image = datamodels.ImageModel(rate_file[1])\n",
    "rateints_cube = datamodels.CubeModel(rateints_file[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that the models are structured this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the structure of the rate file\n",
    "rate_image.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take note of the arrays that we have now:\n",
    "* ```data```\n",
    "* ```dq```\n",
    "* ```err```\n",
    "* ```var_poisson```\n",
    "* ```var_rnoise```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These can be accessed the same way we described before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the science data array for the rate image\n",
    "rate_image.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the science data array for the rateints image\n",
    "rateints_cube.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the variance due to poisson noise \n",
    "variance_poisson = rate_image.var_poisson\n",
    "variance_poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an image of the rate data\n",
    "create_image(rate_image.data, 0, 10, title=\"2D image data product\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare that to an image of one integration for the rateints data\n",
    "create_image(rateints_cube.data[-1,:,:], 0, 10, title=\"3D cube data product\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also examine the ramp for a pixel with the bias drift removed using the optional 4D ```_ramp.fits``` file to revisit the up-the-ramp sampling, with detector corrections applied: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use: integration, pixel_y, pixel_x, group\n",
    "integration = 0\n",
    "pixel_y = 741\n",
    "pixel_x = 1798\n",
    "group = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ramp_file into the RampModel and set up arrays to plot (use: ramp_model, groups, signal_adu)\n",
    "ramp_model = datamodels.RampModel(ramp_file[1])\n",
    "groups = np.arange(0, ramp_model.meta.exposure.ngroups)\n",
    "signal_adu = ramp_model.data[integration, :, pixel_y, pixel_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ramp\n",
    "plot_ramp(groups, signal_adu, xpixel=pixel_x, ypixel=pixel_y, title=\"Optional ramp data product\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the metadata for our output products, but rather than using the standard FITS methods, let's use the data model to access the information. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metadata has been updated after going through Stage 1 processing: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Look at the full metadata list\n",
    "rate_image.meta.instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make note of a few things in the metadata. ```cal_step``` shows you which pipeline steps were applied. You also have the particular calibration reference files that were used for each step, shown in the ```ref_file``` entries. Alternately, you can search the tree for particular keywords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Find datamodel equivalent of the FITS keyword indicating that the linearity correction was done (S_LINEAR)\n",
    "rate_image.find_fits_keyword('S_LINEAR') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search the datamodel for information related to units \n",
    "rate_image.search_schema('unit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the data unit\n",
    "rate_image.meta.bunit_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take a look at some spectroscopic data -- how about a NIRCam WFSS dispersed image? At this stage, the structure will be roughly the same as for our other image example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the WFSS image into the appropriate model (use: wfss_image)\n",
    "wfss_image = datamodels.ImageModel(wfss_rate_file[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an image of the data\n",
    "create_image(wfss_image.data, vmin=-0.05, vmax=0.5, title=\"2D WFSS data before Stage 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the structure of the model\n",
    "wfss_image.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.<font color='white'>-</font>Associations<a class=\"anchor\" id=\"associations\"></a>\n",
    "------------------\n",
    "\n",
    "Now that we're moving on to examine data products for Stage 2 and Stage 3 processing, it would be a good time to mention JWST associations, since the association files are a part of the JWST data products used to process data through Stage 2 and Stage 3. Associations are basically just lists of files, mostly exposures, that are related in some way. For JWST, associations have the following characteristics:\n",
    "\n",
    "* Relationships between multiple exposures are captured in an association.\n",
    "* An association is a means of identifying a set of exposures that belong together and may be dependent upon one another.\n",
    "* The association concept permits exposures to be calibrated, archived, retrieved, and reprocessed as a set rather than as individual objects.\n",
    "\n",
    "In general, it takes many exposures to make up a single observation, and an entire program is made up of a large number of observations. Given a set of exposures for a program, there is a tool that groups the exposures into individual associations. These associations are then used as input to the Stage 2 and 3 calibration steps to perform the transformation from exposure-based data to source-based, high(er) signal-to-noise data. The association used to process data is available in MAST as part of the \"Info\" data product category. You can read more about associations [here](https://jwst-pipeline.readthedocs.io/en/latest/jwst/associations/index.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of a Stage 2 association is shown [in the documentation](https://jwst-pipeline.readthedocs.io/en/latest/jwst/associations/level2_asn_technical.html#example-association), along with a [Stage 3 association](https://jwst-pipeline.readthedocs.io/en/latest/jwst/associations/level3_asn_technical.html#example-association). Unless you are generating your own data or simulations, you will probably not need to create an association file, because you will have the option to retrieve association files from MAST along with your data for reprocessing.  \n",
    "\n",
    "However, if you do want to create an association, there are also [command line tools](https://jwst-pipeline.readthedocs.io/en/latest/jwst/associations/asn_from_list.html) included in the pipeline software that help with generating associations for manually running the pipeline. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that that's out of the way, let's continue our data products journey. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.<font color='white'>-</font>Data products: stage 2 (calibrated exposures)<a class=\"anchor\" id=\"stage2\"></a>\n",
    "------------------\n",
    "\n",
    "The paths through the pipeline begin to diverge during Stage 2 for different observing modes. This stage applies physical corrections and calibrations to individual exposures to produce fully calibrated (unrectified) exposures, and the pipeline module used depends on the exposure type: either imaging or spectroscopy. More information can be found in the [JWST User Documentation](https://jwst-docs.stsci.edu/jwst-data-reduction-pipeline/algorithm-documentation/stages-of-processing). We also have a full list of data product types and the units of the data for each product [in the documentation](https://jwst-pipeline.readthedocs.io/en/latest/jwst/data_products/product_types.html#data-product-types). \n",
    "\n",
    "## 6.1.<font color='white'>-</font>Imaging<a class=\"anchor\" id=\"s2-imaging\"></a>\n",
    "\n",
    "Stage 2 image processing applies additional instrumental corrections and calibrations that result in a fully calibrated individual exposure. Non-time series exposures use the CALWEBB_IMAGE2 module, which applies all applicable steps to the data. The CALWEBB_TSO-IMAGE2 module, on the other hand, should be used for time series exposures, for which some steps are set to be skipped by default. Both modules call the Image2Pipeline; the only difference is which steps are applied.\n",
    "\n",
    "### A.<font color='white'>-</font>Input<a class=\"anchor\" id=\"s2-imaging-input\"></a>\n",
    "\n",
    "The inputs to this stage are listed below.\n",
    "\n",
    "* **2D or 3D countrate data**\n",
    "    * **Data model**: ImageModel or CubeModel\n",
    "    * **File suffix**: ```_rate``` or ```_rateints```\n",
    "    * **Description**: The input to Image2Pipeline is a countrate exposure, either ```_rate``` or ```_rateints``` data. A single input file can be processed or an association file listing multiple inputs can be used, in which case the processing steps will be applied to each input exposure, one at a time. If ```_rateints``` products are used, each step applies its algorithm to each integration in the exposure. Time series and coronagraphic exposures are expected to use 3D data as input, to be processed on a per-integration basis. Time series exposures will use the CALWEBB_TSO2 module, while coronagraphic exposures should use the CALWEBB_IMAGE2 module.\n",
    "    \n",
    "\n",
    "\n",
    "### B.<font color='white'>-</font>Output<a class=\"anchor\" id=\"s2-imaging-output\"></a>\n",
    "\n",
    "The outputs of this stage are listed below.\n",
    "\n",
    "* **2D or 3D calibrated data**\n",
    "    * **Data model**: ImageModel or CubeModel\n",
    "    * **File suffix**: ```_cal``` or ```_calints```\n",
    "    * **Description**: The output is a fully calibrated, but unrectified, exposure, using the product type suffix ```_cal``` or ```_calints```, depending on the type of input.\n",
    "    \n",
    "    \n",
    "* **2D resampled image**\n",
    "    * Data model: DrizProductModel\n",
    "    * File suffix: ```_i2d```\n",
    "    * Description: This is the output of the resample step and is only created for regular direct imaging observations (not for time series or coronagraphy 3D data sets). Note that this product is intended for quick-look use only and is not passed along as input to Stage 3 processing. Calibrated, but unrectified (```_cal```) products are used as input to Stage 3. Here, \"resampled\" just means that rectified 2D images are created using the AstroDrizzle algorithm and the attached WCS information.\n",
    "    \n",
    "   \n",
    "* (optional) **2D or 3D background-subtracted data**\n",
    "    * **Data model**: ImageModel or CubeModel\n",
    "    * **File suffix**: ```_bsub``` or ```_bsubints```\n",
    "    * **Description**: This is an intermediate product that is only created if the ```–save_bsub``` parameter is set to True. It will contain the data as output from the background step. If the input is a ```_rate``` product, this will be a ```_bsub``` product, while ```_rateints``` inputs will be saved as ```_bsubints```.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick look at the standard imaging data product from Stage 2 that is used as input to Stage 3 processing: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the calibrated image into a model (use: cal_image)\n",
    "cal_image = datamodels.ImageModel(cal_file[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the image\n",
    "create_image(cal_image.data[:,:], 0, 10, title=\"2D calibrated image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the model structure\n",
    "cal_image.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the arrays that are available in the calibrated images above:\n",
    "\n",
    "* ```area```\n",
    "* ```data```\n",
    "* ```dq```\n",
    "* ```error```\n",
    "* ```var_flat```\n",
    "* ```var_poisson```\n",
    "* ```var_rnoise```\n",
    "\n",
    "Also notice the ```bunit_data``` and ```bunit_err``` metadata values - those provide the units for the data. The metadata and data arrays can be accessed in the way we described before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the flat variance array\n",
    "variance_flat = cal_image.var_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the units\n",
    "cal_image.meta.bunit_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice in the metadata that there is more information -- for example, the association file name, data units, and WCS information. We'll revisit the WCS in the last section of this module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check out the entire metadata list\n",
    "cal_image.meta.instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2.<font color='white'>-</font>Spectroscopy<a class=\"anchor\" id=\"s2-spectroscopy\"></a>\n",
    "\n",
    "Stage 2 spectroscopic processing applies additional instrumental corrections and calibrations to countrate products that result in a fully calibrated individual exposures. There are two unique configurations (meaning, the steps applied and the order they are applied in) used to control this pipeline, depending on whether the data are to be treated as time series observations. Non-time series exposures use the CALWEBB_SPEC2 configuration, which applies all applicable steps to the data. The CALWEBB_TSO-SPEC2 configuration, on the other hand, should be used for time series exposures, which skips some steps by default. Both configurations call the Spec2Pipeline module; the only difference is which steps are applied.\n",
    "\n",
    "The Spec2Pipeline is the “Swiss army knife” of pipeline modules, containing many steps that are only applied to certain instruments or instrument modes. The logic for determining which steps are appropriate is built into the pipeline module itself and is mostly based on either the instrument name or the exposure type (EXP_TYPE keyword) of the data.\n",
    "\n",
    "### A.<font color='white'>-</font>Input<a class=\"anchor\" id=\"s2-spectroscopy-input\"></a>\n",
    "\n",
    "The inputs to this stage are listed below.\n",
    "\n",
    "* **2D or 3D countrate data**\n",
    "    * **Data model**: ImageModel, IFUImageModel, or CubeModel\n",
    "    * **File suffix**: ```_rate``` or ```_rateints```\n",
    "    * **Description**: The input to the Spec2Pipeline pipeline is a countrate exposure, either ```_rate``` or ```_rateints``` data. A single input file can be processed or an association file listing multiple inputs can be used, in which case the processing steps will be applied to each input exposure, one at a time. If ```_rateints``` products are used as input, each step applies its algorithm to each integration in the exposure. Note that some steps can only be executed when the pipeline is given an association file as input, because they rely on multiple, associated exposures to perform their tasks. The association file must list not only the input science exposure(s), but must also list the exposures to be used as background or imprint. The input data model type IFUImageModel is only used for MIRI MRS and NIRSpec IFU exposures.\n",
    "    \n",
    "\n",
    "### B.<font color='white'>-</font>Output<a class=\"anchor\" id=\"s2-spectroscopy-output\"></a>\n",
    "\n",
    "The outputs of this stage are listed below.\n",
    "\n",
    "* **2D or 3D calibrated data**\n",
    "    * **Data model**: ImageModel, IFUImageModel, CubeModel, SlitModel, or MultiSlitModel\n",
    "    * **File suffix**: ```_cal``` or ```_calints```\n",
    "    * **Description**: The output is a fully calibrated, but unrectified, exposure, using the product type suffix ```_cal``` or ```_calints```, dependening on the type of input.The output data model type can be any of the 4 listed above and is completely dependent on the type of input data and the observing mode. For data sets that do not go through 2D spectral extraction, the output will be either a ImageModel, IFUImageModel, or CubeModel, matching the corresponding input data type. Of the data types that do go through extract_2d processing, the output type will consist of either a single slit model or a mutli-slit model:\n",
    "\n",
    "* NIRSpec Bright-Object and NIRCam TSO Grism: SlitModel\n",
    "* NIRSpec Fixed Slit and MOS, as well as WFSS: MultiSlitModel\n",
    "\n",
    "The multi-slit model is an array of multiple slit models, each one containing the data and relevant metadata for a particular extracted slit or source. A MultiSlitModel product will contain multiple tuples of SCI, ERR, DQ, WAVELENGTH, etc. arrays; one for each of the extracted slits/sources.\n",
    "    \n",
    "    \n",
    "* **2D resampled data**\n",
    "    * Data model: DrizProductModel or MultiProductModel\n",
    "    * File suffix: ```_s2d```\n",
    "    * Description: If the input is a 2D exposure type that gets resampled/rectified, the rectified 2D spectral product is saved as a ```_s2d``` file. This image is intended for use as a quick-look product only and is not used in subsequent processing. The 2D unresampled, calibrated (```_cal```) products are passed along as input to subsequent Stage 3 processing. If the input is a MultiSlitModel, then the resampled output will be in the form of a MultiProductModel, which contains an array of individual models, one per slit. Otherwise the output will be a DrizProductModel. Here, \"resampled\" just means that rectified 2D images are created using the AstroDrizzle algorithm and the attached WCS information.\n",
    "    \n",
    "    \n",
    "* **3D resampled (IFU cube) data**\n",
    "    * Data model: IFUCubeModel\n",
    "    * File suffix: ```_s3d```\n",
    "    * Description: If the data are NIRSpec IFU or MIRI MRS, the result of the cube building step will be a 3D IFU spectroscopic cube saved to a ```_s3d``` file. The IFU cube is built from the data contained in a single exposure and is intended for use as a quick-look product only and is not used in subsequent processing. The 2D unresampled, calibrated (```_cal```) products are passed along as input to subsequent Stage 3 processing.\n",
    "    \n",
    "    \n",
    "* **1D extracted spectral data**\n",
    "    * Data model: MultiSpecModel\n",
    "    * File suffix: ```_x1d``` or ```_x1dints```\n",
    "    * Description: All types of inputs result in a 1D extracted spectral data product, which is saved as a ```_x1d``` or ```_x1dints``` file, depending on the input type. Observing modes such as MIRI LRS fixed slit and MRS, NIRCam and NIRISS WFSS, and NIRSpec fixed slit, MOS, and IFU result in an ```_x1d``` product containing extracted spectral data for one or more slits/sources. Time series modes, such as MIRI LRS slitless, NIRCam time series grism, NIRISS SOSS, and NIRSpec Bright Object, for which the data are 3D stacks of integrations, result in ```_x1dints``` products containing extracted spectral data for each integration with the exposure.\n",
    "    \n",
    "   \n",
    "* (optional) **2D or 3D background-subtracted data**\n",
    "    * **Data model**: ImageModel, IFUImageModel, or CubeModel\n",
    "    * **File suffix**: ```_bsub``` or ```_bsubints```\n",
    "    * **Description**: This is an intermediate product that is only created if the ```–save_bsub``` parameter is set to True. It will contain the data as output from the background step. If the input is a ```_rate``` product, this will be a ```_bsub``` product, while ```_rateints``` inputs will be saved as ```_bsubints```.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's revisit our NIRCam WFSS data from before, but this time we'll look at the ```_cal.fits``` calibrated output from Stage 2 that is used as input to Stage 3. It's going to look a little different. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the calibrated WFSS data into a model (use: cal_wfss) \n",
    "cal_wfss = datamodels.MultiSpecModel(wfss_cal_file[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the structure\n",
    "cal_wfss.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we no longer have the ```data``` array, because the model contains extracted spectral data for one or more slits/sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# What's in slits?\n",
    "cal_wfss.slits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can examine the information for the different slits, e.g., the photometric conversion used, pixel area, etc.):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Choose a slit, say slit #10, and check out all the meta data (use: slit_number)\n",
    "slit_number = 12\n",
    "cal_wfss.slits[slit_number].meta.instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the source ID, spectral order, bounding box, source position, and data mean\n",
    "print('\\nSlit number: ', slit_number)\n",
    "print('Source ID: ', cal_wfss.slits[slit_number].source_id)\n",
    "print('Spectral order: ', cal_wfss.slits[slit_number].meta.wcsinfo.spectral_order)\n",
    "print('Bounding box: ', cal_wfss.slits[slit_number].meta.wcs.bounding_box)\n",
    "print('Source X position, Y position (full frame coordinates): ', cal_wfss.slits[slit_number].source_xpos,cal_wfss.slits[slit_number].source_ypos)\n",
    "print('Data average: ', cal_wfss.slits[slit_number].data.mean())\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the WCS information for a particular column and row (use: column, row, ra, dec, wavelength, order)\n",
    "column, row = 100, 4\n",
    "ra, dec, wavelength, order = cal_wfss.slits[slit_number].meta.wcs(column, row)\n",
    "print('RA: ', ra)\n",
    "print('Dec: ', dec)\n",
    "print('Wavelength: ',wavelength)\n",
    "print('Order: ',order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this slit look like? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an image of this slit\n",
    "create_slit_image(cal_wfss, slit_number, vmin=-0.1, vmax=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "Or plot one column of the dispersed image for our slit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot one column of the slit\n",
    "plot_column(cal_wfss.slits[slit_number].data, column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the 1D extracted spectral data product, the ```_x1d.fits``` file? At first glance using FITS, this file can appear very complicated because there is one extension for each source and spectral order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Use FITS to examine the structure of this file \n",
    "with fits.open(wfss_x1d_file[1]) as h:\n",
    "    h.info()\n",
    "    for i in np.arange(1,len(h)-1):\n",
    "        print('\\nExtension: ',i)\n",
    "        print('Source ID: ',h[i].header['SOURCEID'])                \n",
    "        print('Spectral Order: ',h[i].header['SPORDER'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the ```MultiSpecModel``` makes it much easier to work with this file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to a datamodel (use: spec)\n",
    "spec = datamodels.MultiSpecModel(wfss_x1d_file[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What's the shape of spec.spec?\n",
    "print(len(spec.spec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can choose our source and the spectral order, and plot the spectrum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the source ID and spectral order, just use the same slit_number\n",
    "print('Source ID: ', spec.spec[slit_number].source_id)\n",
    "print('Spectral order: ', spec.spec[slit_number].spectral_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the spectrum\n",
    "plot_spectra(spec, slit_number, median_filter=11)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.<font color='white'>-</font>WCS deep dive<a class=\"anchor\" id=\"wcs\"></a>\n",
    "------------------\n",
    "\n",
    "The first step in Stage 2 processing (\"Assign WCS\") is where the information to transfer the pixel coordinates to astronomical coordinates (e.g., RA and Dec) is added to the data. The WCS information and distortion model are provided by instrument- and detector- specific calibration reference files. The data itself is not modified by this step, it just associates a WCS object with each science exposure. The WCS object transforms positions in the detector frame to positions in a world coordinate frame - ICRS and wavelength. In general, there may be intermediate coordinate frames depending on the instrument. The WCS is saved in the ASDF extension of the FITS file and can be accessed as an attribute of the meta object when the FITS file is opened as a data model.\n",
    "\n",
    "#### From the FITS WCS standard to the Generalized World Coordinate System (GWCS)\n",
    "\n",
    "The JWST Assign WCS step is based on [GWCS](https://gwcs.readthedocs.io/en/latest/) and uses the modeling, units and coordinates subpackages in Astropy. GWCS provides a more general approach to the problem of expressing transformations between pixel and world coordinates. It supports a data model that includes the entire transformation pipeline from input coordinates (detector by default) to world coordinates and is tightly integrated with Astropy, rather than using the FITS WCS standard, which only provides instructions on how to relate pixel to world. GWCS will provide observers with the complete transform. \n",
    "\n",
    "The forward direction of the transforms is from detector to world coordinates and the input positions are 0-based. Basic WCS keywords are contained in the science headers, while distortion and spectral models are stored in reference files in the ASDF format.\n",
    "\n",
    "For each observing mode, the \"Assign WCS\" step (or ```assign_wcs```) retrieves calibration reference files and creates a pipeline of transforms from the input detector frame to the V2,V3 frame. This part of the WCS pipeline may include intermediate coordinate frames. The basic WCS keywords are used to create the transform from V2,V3 frame to world coordinates.\n",
    "\n",
    "To display images with software like DS9 that relies on specific WCS information, a SIP-based approximation to the WCS is fit. The results are FITS keywords stored in ```model.meta.wcsinfo```. While this is not an exact fit, it is accurate to ~0.25 pixel and should be sufficient for display purposes. This step is performed by default, but observers can turn it off manually or adjust the parameters that control the fit. This step will be discussed more in the pipeline tutorial JWebbinars. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the imaging example to interact with the WCS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the Assign WCS step is run in Stage 2, a GWCS object that contains all the transforms is now attached to the image model. What does the GWCS WCS look like? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the WCS info in the calibrated image model \n",
    "cal_image.meta.wcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does this compare to the FITS WCS standard?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does this compare to the FITS wcs? (use: image_fits_wcs)\n",
    "image_fits_wcs = cal_image.get_fits_wcs()\n",
    "image_fits_wcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare that with the WCS information in the datamodel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at CRVAL and CRPIX in the datamodel\n",
    "print('CRVAL: ', cal_image.meta.wcsinfo.crval1, cal_image.meta.wcsinfo.crval2)\n",
    "print('CRPIX: ', cal_image.meta.wcsinfo.crpix1, cal_image.meta.wcsinfo.crpix2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see what coordinate frames are available to you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What coordinate frames are available?\n",
    "cal_image.meta.wcs.available_frames  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What was the input frame for this data?\n",
    "cal_image.meta.wcs.input_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What was the output frame?\n",
    "cal_image.meta.wcs.output_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the transform from detector pixels to sky coordinates in decimal degrees of RA and Dec: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the WCS info for pixel 110, 110\n",
    "cal_image.meta.wcs(110, 110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the transform to go from detector to world coordinates (use: detector_to_world)\n",
    "detector_to_world = cal_image.meta.wcs.get_transform('detector', 'world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the transformation for our pixel (use: pix_ra, pix_dec)\n",
    "pix_ra, pix_dec = detector_to_world(110, 110)\n",
    "pix_ra, pix_dec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the inverse transform: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now get the reverse transform from world to detector (use: world_to_detector)\n",
    "world_to_detector = cal_image.meta.wcs.get_transform('world', 'detector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the transformation using our outputs from above\n",
    "world_to_detector(pix_ra, pix_dec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about our spectral data? Let's take a look: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What frames are available?\n",
    "cal_wfss.slits[slit_number].meta.wcs.available_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What was the bounding box used for the cutout?\n",
    "cal_wfss.slits[slit_number].meta.wcs.bounding_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at CRVAL and CRPIX in the datamodel\n",
    "print('CRVAL: ', cal_wfss.meta.wcsinfo.crval1, cal_wfss.meta.wcsinfo.crval2)\n",
    "print('CRPIX: ', cal_wfss.meta.wcsinfo.crpix1, cal_wfss.meta.wcsinfo.crpix2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the WCS info for multiple pixels: (200, 4) and (30, 3) -- (use: ra, dec, wavelength, order)\n",
    "ra, dec, wavelength, order = cal_wfss.slits[slit_number].meta.wcs([10, 4], [6, 3])\n",
    "ra, dec, wavelength, order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can do the backwards transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the world to detector transform (use: world_to_detector_ss)\n",
    "world_to_detector_ss = cal_wfss.slits[slit_number].meta.wcs.get_transform('world','detector') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And go from world to detector coordinates (use: x0, y0, wave, order2)\n",
    "x0, y0, wave, order2 = world_to_detector_ss(ra, dec, wavelength, order)\n",
    "print(x0, y0, wave, order2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the forward transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, do the inverse (use: detector_to_world_ss)\n",
    "detector_to_world_ss = cal_wfss.slits[slit_number].meta.wcs.get_transform('detector','world')\n",
    "detector_to_world_ss(x0, y0, wave, order2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next and final module will discuss the Stage 3 data products, the last stage of processing in the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.<font color='white'>-</font>Exercise<a class=\"anchor\" id=\"exercise\"></a>\n",
    "--------------------------------------------------------------------\n",
    "Now, you try it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the exercise data using a model\n",
    "with datamodels.open(demo_ex_file[1]) as exercise_data:\n",
    "    exercise_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What instrument and mode are used here?\n",
    "exercise_data.meta.instrument.name, exercise_data.meta.exposure.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the data units? \n",
    "exercise_data.meta.bunit_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which calibration steps were applied?\n",
    "exercise_data.meta.cal_step.instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a pixel or pixels and get the WCS information\n",
    "det_x, det_y = 10, 5\n",
    "ra, dec, wave, order = exercise_data.slits[0].meta.wcs(det_x, det_y)\n",
    "ra, dec, wave, order "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now get the detector to world transform\n",
    "d2w = exercise_data.slits[0].meta.wcs.get_transform('detector','world') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the transformormation\n",
    "ra, dec, wavelength, order = d2w(det_x, det_y, wave, order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now get the inverse transform\n",
    "w2d = exercise_data.slits[0].meta.wcs.get_transform('world','detector') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the transformation - do you get your pixel back? \n",
    "w2d(ra, dec, wavelength, order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Page](#title_ID)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
