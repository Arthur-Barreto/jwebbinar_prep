{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e21d550",
   "metadata": {},
   "source": [
    "<img style=\"float: center;\" src='https://github.com/STScI-MIRI/MRS-ExampleNB/raw/main/assets/banner1.png' alt=\"stsci_logo\" width=\"1000px\"/> \n",
    "\n",
    "# TSO JWebbinar Notebook 2: Exploring TSO Products\n",
    "-----\n",
    "\n",
    "**Author**: NÃ©stor Espinoza, AURA Assistant Astronomer, NIRISS branch\n",
    "<br>\n",
    "**Last Updated**: November 12, 2021\n",
    "<br>\n",
    "**Pipeline Version**: x.x.x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc24f5c",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "1. [Introduction](#intro)<br>\n",
    "   1.1 [Purpose of this Notebook](#purpose)<br>\n",
    "   1.2 [Input Simulations](#inputs)<br>\n",
    "   1.3 [Caveats for Simulated Data](#nirisscaveats)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0a705b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "1.<font color='white'>-</font>Introduction <a class=\"anchor\" id=\"intro\"></a>\n",
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffeef35",
   "metadata": {},
   "source": [
    "### 1.1<font color='white'>-</font>Purpose of this Notebook<a class=\"anchor\" id=\"purpose\"></a> ###\n",
    "\n",
    "In this notebook we provide material to get started on the exploration of TSO products; in particular, we focus on outputs from `detector1` and the `spec2` stages of the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc00ab4",
   "metadata": {},
   "source": [
    "### 1.2<font color='white'>-</font>Input Simulations<a class=\"anchor\" id=\"inputs\"></a> ###\n",
    "\n",
    "The input data for this notebook are simulations made by the NIRISS/SOSS team of a transit of WASP-43b. These simulations were made using the [`mirage`](https://mirage-data-simulator.readthedocs.io/en/latest/) simulator. This dataset can be found [here](https://stsci.app.box.com/folder/135937177294?s=6gegobzzkr8xuptgy0udodob9hq4kvi1).\n",
    "\n",
    "We will be using products at three different stages of the pipeline, namely:\n",
    "\n",
    "1. **The Uncalibrated Products**. These correspond to data that have not yet been passed through any of the stages of the pipeline. These have `*uncal.fits` extensions.\n",
    "2. **The Stage 1 Calibrated Products**. These corrspond to data that have been passed through the `detector1` stage of the pipeline and contain the slopes of the up-the-ramp samples for each integration. These have `*_1_rampfitset.fits` extension.\n",
    "3. **The partially Stage 2 Calibrated Products**. These correspond to data that have only been calibrated up to the `assign_wcs` step, with which one can obtain the wavelength map of the spectra. These have `*_1_assignwcsstep.fits` extensions.\n",
    "\n",
    "These products are downloaded directly from this notebook below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82389a0",
   "metadata": {},
   "source": [
    "### 1.3<font color='white'>-</font>Caveats for Simulated Data<a class=\"anchor\" id=\"mirisim\"></a> ###\n",
    "\n",
    "The [`mirage`](https://mirage-data-simulator.readthedocs.io/en/latest/) simulator is not perfect. Be aware that how close these simulations are to real data is not going to be perfectly known until we obtain on-sky data with JWST. As such, a big disclaimer is that while `mirage` simulations represent a large fraction of the systematics that we expect to see, it is in no way a guarantee that this will be the full picture of what we will _actually_ see on real JWST data.\n",
    "\n",
    "Also note that time-series systematics have not been added to those simulations. This has been important for previous observatories to consider, and appear due to, e.g., thermal breathing of the instruments, focus changes, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f3de65",
   "metadata": {},
   "source": [
    "2.<font color='white'>-</font>Setup <a class=\"anchor\" id=\"setup\"></a>\n",
    "------------------\n",
    "\n",
    "In this section we set things up a number of necessary things in order for the pipeline to run successfully.\n",
    "\n",
    "First we'll set the CRDS context; this dictates the versions of various pipeline reference files to use.  Ordinarily you wouldn't want to set a specific version as the latest pipeline should already use the most-recent reference files (and hard-coding a version could get you old reference files that have since been replaced).  However, since this demo is using an old version 1.1.0 of the pipeline, we need to tell it to get some more recent reference files.\n",
    "\n",
    "Next we'll import the various python packages that we're actually going to use in this notebook, including both generic utility functions and the actual pipeline modules themselves.\n",
    "\n",
    "Next, we'll specify the data directory structure that we want to use.  In order to keep our filesystem clean we'll separate simulated inputs and outputs from each pipeline stage into their own folders.\n",
    "\n",
    "Finally, for convenience in this JWebbinar we'll define a flag that sets whether or not to actually run some of the longer pipeline steps in this notebook or just to rely upon cached reductions provided ahead of time.  This is because a number of steps (particularly building 3d data cubes) can take quite a long time to run, and in a short Webbinar we don't want to be waiting for them to all run in real time.  This flag is set to False by default for use in the live Webbinar; if you want to experiment with running all steps yourself ahead of time just set this flag to True.  Total notebook runtime with True/False values is about 1.5 hours vs 3 minutes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c084f9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to set these enviromental variables for this notebook to work properly:\n",
    "%set_env CRDS_PATH $HOME/crds_cache\n",
    "%set_env CRDS_SERVER_URL https://jwst-crds.stsci.edu\n",
    "\n",
    "# Import all useful libraries:\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.polynomial import chebyshev\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from mpl_toolkits.axes_grid1.inset_locator import mark_inset\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "from jwst import datamodels\n",
    "from astropy.io import fits\n",
    "from astropy.utils.data import download_file\n",
    "\n",
    "from jwst.pipeline import calwebb_detector1\n",
    "from jwst.pipeline import calwebb_spec2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49194a6",
   "metadata": {},
   "source": [
    "3.<font color='white'>-</font>A tour through the `Detector1` stage <a class=\"anchor\" id=\"setup\"></a>\n",
    "------------------\n",
    "\n",
    "Here, we will play with one segment of the Uncalibrated data. Let's first download this file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a0097f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download uncal file:\n",
    "file_link = 'https://stsci.box.com/shared/static/dy0t8hza8tzpoqcdlny54e9y6pbsjctc.fits'\n",
    "filename = 'WASP43_NIS_SOSS-seg002_CLEAR_uncal.fits'\n",
    "\n",
    "# Look if the file has been downloaded. If not, do it:\n",
    "if os.path.isdir(filename):\n",
    "    \n",
    "    print(filename + ' already exists. Not downloading.')\n",
    "\n",
    "else:\n",
    "    \n",
    "    print('Downloading {}...'.format(filename))\n",
    "    download_filename = download_file(file_link, cache=True)\n",
    "    # Rename file:\n",
    "    os.rename(download_filename, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1530410f",
   "metadata": {},
   "source": [
    "Let's load the data inside a JWST `datamodel`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b4af42",
   "metadata": {},
   "outputs": [],
   "source": [
    "uncal_data = datamodels.open(\"WASP43_NIS_SOSS-seg002_CLEAR_uncal.fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f190a25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cover a bug that exists given the simulated data was created a while ago. This will not be \n",
    "# needed to be done on real data, but it's a nice excercise showing how easy it is to deal \n",
    "# with JWST datamodels:\n",
    "uncal_data.meta.dither.dither_points = int(uncal_data.meta.dither.dither_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a184ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's run the DQ init step --- this will assign DQ flags to our fits uncal file. \n",
    "# First, create output directory:\n",
    "os.mkdir('pipeline_outputs_directory')\n",
    "\n",
    "# Run step:\n",
    "dq_results = calwebb_detector1.dq_init_step.DQInitStep.call(uncal_data, \n",
    "                                                            output_dir='pipeline_outputs_directory', \n",
    "                                                            save_results=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beafc717",
   "metadata": {},
   "source": [
    "Let's run the `saturation` and `linearity` steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b70e61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
